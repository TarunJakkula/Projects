{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70756f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.layers import Flatten,AveragePooling2D,Dense,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "data='D:\\Destination\\dataset'\n",
    "category=[\"New_Front\",\"New_Rear\",\"Old_Front\",\"Old_Rear\"]\n",
    "#category2=['video_data']\n",
    "IMG_SIZE=227\n",
    "test=[]\n",
    "train = []\n",
    "def create_training_data(t,d,c):\n",
    "    for cat in c:\n",
    "        path = os.path.join(d, cat)\n",
    "        class_num = c.index(cat)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))\n",
    "                new_array = cv2.resize(img_array,(IMG_SIZE, IMG_SIZE))\n",
    "                t.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return t\n",
    "train=create_training_data(train,data,category)\n",
    "#test=create_training_data(test,data,category2)\n",
    "\n",
    "def process_images(image, label):\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    image = tf.image.resize(image, (227,227))\n",
    "    return image, label\n",
    "\n",
    "\n",
    "random.shuffle(train)\n",
    "x=[]\n",
    "y=[]\n",
    "for feat, label in train:\n",
    "    x.append(feat)\n",
    "    y.append(label)\n",
    "x=np.array(x).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "y=np.array(y)\n",
    "x=x/255.0\n",
    "validation_images, validation_labels = x[:285], y[:285]\n",
    "train_images, train_labels = x[285:], y[285:]\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "train_ds = (train_ds.map(process_images).batch(batch_size=32, drop_remainder=True))\n",
    "validation_ds = (validation_ds.map(process_images).batch(batch_size=32, drop_remainder=True))\n",
    "\n",
    "\"\"\"\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "for feat, label in test:\n",
    "    x_test.append(feat)\n",
    "    y_test.append(label)\n",
    "x_test=np.array(x_test).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "y_test=np.array(y_test)\n",
    "x_test=x_test/255.0\n",
    "\"\"\"\n",
    "\n",
    "baseModel = MobileNetV2(input_shape=[227,227,3], weights=\"imagenet\",include_top=False)\n",
    "x=baseModel.output\n",
    "x=AveragePooling2D(pool_size=(7,7))(x)\n",
    "x= Flatten(name=\"flatten\")(x)\n",
    "x= Dense(4096, activation='relu')(x)\n",
    "x= Dropout(0.5)(x)\n",
    "x= Dense(4096, activation='sigmoid')(x)\n",
    "x= Dropout(0.5)(x)\n",
    "x= Dense(4, activation='softmax')(x)\n",
    "model = Model(inputs=baseModel.input,outputs=x)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
    "model.fit(train_ds,epochs=10,validation_data=validation_ds)\n",
    "\n",
    "#results = model.evaluate(x_test, y_test, batch_size=32)\n",
    "#print(\"test loss, test acc:\", results)\n",
    "\n",
    "#prediction = model.predict(x_test[:1])\n",
    "#print(\"prediction shape:\", prediction.shape)\n",
    "\n",
    "\n",
    "# Saving and loading model and weights\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# serialize model to JSON\n",
    "model_all_json = model.to_json()\n",
    "with open(\"model_all.json\", \"w\") as json_file:\n",
    "    json_file.write(model_all_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_all.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model_all.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_all.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "model.save('model_all.hdf5')\n",
    "loaded_model=load_model('model_all.hdf5')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
